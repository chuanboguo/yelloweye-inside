## SIMULATION OF THE APPLICATION OF MANAGEMENT PROCEDURES {#sec:simulation}

```{r rversion}
rversion <- gsub(" \\([0-9-]+\\)", "", devtools::session_info()$platform$version)
```

We ran the closed-loop simulations across 250 stochastic replicates using DLMtool version 5.4.2, `r rversion`, and the simulation random seed set to `1`, with the OMs and MPs described above.
We assessed convergence of the closed-loop simulation by plotting the cumulative performance metrics as replicates were added (Figure \@ref(fig:converge)).
We deemed 250 replicates sufficient since the rank order of MPs was consistent for this number of replicates (Figure \@ref(fig:converge)).

(ref:fig-converge)
Assessing convergence of the closed-loop simulations on consistent rank order of MPs within performance metrics.
Colours represent individual satisficed and reference MPs.
Lines that do not cross by the final replicates indicate that rank order among replicates has converged.
Although not shown, we also checked that the satisficing rules had converged (i.e., the selection of satisficed MPs did not change with additional replicates).

```{r converge, fig.cap="(ref:fig-converge)", out.width="\\textwidth"}
knitr::include_graphics(here("mse/figures/ye-convergence.png"))
```

```{r mp-sat}
pm_df_list <- readRDS(here("mse/om/ye-pm-all.rds"))
pm_all <- bind_rows(pm_df_list, .id = "scenario")
pm_avg <- group_by(pm_all, MP) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)
pm_min <- group_by(pm_all, MP) %>%
  summarise_if(is.numeric, min, na.rm = TRUE)
reference_mp <- c("FMSYref75", "NFref", "FMSYref")

satisficed_criteria <- c("LRP 1.5GT" = 0.9, "ST C10" = 0.5)
mp_sat <- dplyr::filter(pm_min, `LRP 1.5GT` > satisficed_criteria[1], `ST C10` > satisficed_criteria[2]) %>%
  pull(MP)
mp_sat <- mp_sat[!mp_sat %in% reference_mp]

pm_avg_sat <- pm_avg %>% filter(MP %in% mp_sat)
pm_min_sat <- pm_min %>% filter(MP %in% mp_sat)
```

To determine which MPs would be carried forward as satisficed MPs [@miller2010], we began by assessing average and minimum performance across all candidate MPs for the reference set of OMs (Figures \@ref(fig:tigure-avg) and \@ref(fig:tigure-min)).
All MPs met the satisficing criterion (LRP 1.5GT > 0.95) in individual OMs in the reference set and averaged across all four reference OMs (Figures \@ref(fig:tigure-avg) and \@ref(fig:tigure-min)).
Since many MPs also generated low catches, we applied an additional satisficing filter retaining only MPs where ST C10 > 50%.
This left us with Fixed TACs of 10 and 15 t and Islope MPs.

We chose to apply the satisficing criteria to the average performance metrics.
Applying these criteria resulted in `r gfutilities::number_to_word(length(mp_sat))` remaining MPs (`r gfutilities::commify(sort(mp_sat))`).

(ref:fig-tigure-avg) Average performance of all candidate MPs across the reference set of OMs.
MPs are ordered by decreasing performance metric values from top to bottom starting with the left-most performance metric (LT LRP) and using columns from left to right to break any ties.
The colour shading reflects the probabilities.
Outlined cells represent MPs that met a particular performance metric's satisficing criteria.
Using this set of criteria, MPs would be "satisficed" if cells in *both* "`r names(satisficed_criteria)[1]`" and "`r names(satisficed_criteria)[2]`" were outlined.
Light grey MPs indicate reference MPs.

```{r tigure-avg, fig.cap="(ref:fig-tigure-avg)", out.width="3.5in"}
knitr::include_graphics(here("mse/figures/ye-tigure-refset-avg.png"))
```

(ref:fig-tigure-min) Minimum performance of all candidate MPs across the reference set of OMs.
This figure is the same as Figure \@ref(fig:tigure-avg) but shows the **minimum** performance metric across the OMs in the reference set for the purposes of applying satisficing rules.
In other words, this figure illustrates the worst performance of each MP across the reference set of OMs.

```{r tigure-min, fig.cap="(ref:fig-tigure-min)", out.width="3.5in"}
knitr::include_graphics(here("mse/figures/ye-tigure-refset-min.png"))
```

- Iratio generates low catches within the first decade but generates high catches later on. There is high variability among replicates in each OM.
- IDX returns gradually lower catches over time.
- GB_slope appears to hold catch fairly constant between 10-15 t in the reference set.
- Iratio and GB_slope generates zero catch in the low catch OM. Hence it didn't satisfy the informal `ST C10` performance metric
- SP MPs generate no catch in the first decade, but increase catches later on, e.g. after 50 years.
Iratio and GB_slope generates zero catch in the low catch OM. Hence it didn't satisfy the `ST C10` performance metric
